{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36fbec26",
   "metadata": {},
   "source": [
    "<!--Copyright © ZOMI 适用于[License](https://github.com/Infrasys-AI/AIInfra)版权许可-->\n",
    "\n",
    "# 用 RAGFlow 实现中文文档问答\n",
    "\n",
    "RAG（Retrieval-Augmented Generation，检索增强生成）是一种“先找资料、再答问题”的 AI 技术——就像我们写作业时先查参考书，再组织答案一样。它能让 AI 在回答特定问题时，不再只依赖“记忆”，而是从真实文档中获取准确信息，避免“胡编乱造”。\n",
    "\n",
    "假设你正在负责图书答疑，有读者询问某本书中特定主题的问题：\n",
    "\n",
    "情景 1：读者直接向你提问，但你并不知道他所说的是哪本书，不过，凭借丰富的知识储备，你还是给出了一个回答。\n",
    "\n",
    "![](./images/CODE02RAGFlow01.png)\n",
    "\n",
    "情景 2：读者先向你的助理提问，助理从书架上找出了相关的书籍，检索到了他认为相关的段落，并将这些段落和问题一起交给你，基于这些具体的信息，你提供了一个更加准确、相关且详细的回答。\n",
    "\n",
    "![](./images/CODE02RAGFlow02.png)\n",
    "\n",
    "情景 2 就是 RAG 的工作方式：在模型回答之前，先检索相关的信息提供给模型，以增强其回答的准确性和相关性。\n",
    "\n",
    "因此，\"检索增强\"更像是一种工程上的操作，或者说是对 Prompt 的增强，并不会影响模型本身的参数。通过在 Prompt 中加入检索到的相关信息，模型可以在回答特定文档的问题时表现得更好。有点像将 Zero-shot Prompting 扩充为 Few-shot Prompting，所以在特定文档的问答中会有提升。而 \"增强\" 就是大家熟悉的文本生成，或者说生成式模型的调用（本文不会涉及模型训练）。\n",
    "\n",
    "## 1. 增强检索\n",
    "\n",
    "本实验将用 **公开中文数据集**、**在线可下载模型** 和 **RAGFlow 工具**，一步步实现一个完整的 RAG 问答系统。全程代码简单、注释详细，即使是刚接触 AI 的初学者也能跟着跑通。\n",
    "\n",
    "基于“中文维基百科公开数据集”，搭建一个能回答“人物成就、事件时间”等事实性问题的 RAG 系统，比如：\n",
    "\n",
    "- 问：“爱因斯坦因什么获得诺贝尔奖？”\n",
    "- 系统会从维基文档中检索相关内容，再生成准确回答。\n",
    "\n",
    "在实际实现中，遵循的步骤大致如下：\n",
    "\n",
    "使用预训练的编码器模型将「文档」内容编码为向量表示（embedding），然后建立一个向量数据库。\n",
    "在检索阶段，针对用户的「问题」，同样使用编码器将其编码为向量，然后在向量数据库中寻找与之相似的文档片段。\n",
    "\n",
    "### 1.1. 环境准备\n",
    "\n",
    "首先安装实验需要的工具库，复制代码到终端运行即可（推荐用 Python 3.9+）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# 核心库：RAGFlow（RAG 流程工具）、datasets（加载公开数据）\n",
    "pip install ragflow pandas datasets\n",
    "\n",
    "# 模型相关：transformers（加载 AI 模型）、sentence-transformers（文本编码）\n",
    "pip install transformers sentence-transformers accelerate\n",
    "\n",
    "# 向量数据库：FAISS（轻量级，支持 CPU/GPU）\n",
    "pip install faiss-gpu\n",
    "\n",
    "# 辅助库：避免文本处理报错\n",
    "pip install nltk \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83956c",
   "metadata": {},
   "source": [
    "然后运行以下代码，下载必要的分词数据（避免后续报错）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3a6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266461a5",
   "metadata": {},
   "source": [
    "### 1.2 加载数据集\n",
    "\n",
    "我们用“中文维基百科公开数据集”（包含 100 万+中文文档片段，无需本地文件，在线直接加载），这里取前 100 条数据（避免电脑跑不动）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa5b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset  # 加载公开数据集的工具\n",
    "from ragflow.schema import Document  # RAGFlow 的文档格式类\n",
    "\n",
    "# 1. 加载中文维基数据集（在线下载，首次运行可能需要 1-2 分钟）\n",
    "# 数据集来源：Hugging Face（AI 领域常用的公开数据平台）\n",
    "dataset = load_dataset(\"lcw99/wikipedia-zh-20230720\", split=\"train[:100]\")\n",
    "\n",
    "# 2. 转换为 RAGFlow 能识别的格式（每个文档包含“内容”和“元数据”）\n",
    "documents = []\n",
    "for idx, data in enumerate(dataset):\n",
    "    # 构建单个文档：page_content 是核心文本，metadata 是辅助信息（如标题、来源）\n",
    "    doc = Document(\n",
    "        page_content=data[\"text\"],  # 文档正文\n",
    "        metadata={\n",
    "            \"title\": data[\"title\"],  # 文档标题（比如“阿尔伯特·爱因斯坦”）\n",
    "            \"source\": \"中文维基百科\",  # 数据来源（方便溯源）\n",
    "            \"id\": idx  # 唯一编号（避免重复）\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "\n",
    "# 验证：打印第一条文档的前 200 字，确认加载成功\n",
    "print(\"加载的文档示例：\")\n",
    "print(f\"标题：{documents[0].metadata['title']}\")\n",
    "print(f\"内容：{documents[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc557ba4",
   "metadata": {},
   "source": [
    "**运行结果示例**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bc1e5b",
   "metadata": {
    "attributes": {
     "classes": [
      "text"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "加载的文档示例：\n",
    "标题：阿尔伯特·爱因斯坦\n",
    "内容：阿尔伯特·爱因斯坦（德语：Albert Einstein，1879 年 3 月 14 日－1955 年 4 月 18 日），犹太裔理论物理学家，创立了狭义相对论和广义相对论，被公认为是现代物理学之父。他的质能方程 E=mc²是物理学中最著名的方程之一..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0a2391",
   "metadata": {},
   "source": [
    "### 1.3 进行文本分块\n",
    "\n",
    "长文档直接喂给 AI 会“记不住”，我们需要把文档切成短片段（叫“chunk”），就像把一本书拆成章节一样。\n",
    "\n",
    "![](./images/CODE02RAGFlow03.png)\n",
    "\n",
    "这里用 RAGFlow 的`RecursiveCharacterTextSplitter`工具，按中文语义逻辑分块："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779bdf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragflow.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. 配置分块工具（参数专为中文优化）\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,    # 每个片段最多 500 字（太长 AI 处理慢，太短语义不完整）\n",
    "    chunk_overlap=50,  # 片段间重叠 50 字（避免切断句子，比如“爱因斯坦”不会一半在 A 段、一半在 B 段）\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"。\", \"，\", \" \"]  # 优先按“段落→句子→逗号”分割（符合中文阅读习惯）\n",
    ")\n",
    "\n",
    "# 2. 对所有文档进行分块\n",
    "docs_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 验证：查看分块结果\n",
    "print(f\"原始文档数量：{len(documents)}\")\n",
    "print(f\"分块后片段数量：{len(docs_chunks)}\")\n",
    "print(f\"\\n 第一个片段示例：\")\n",
    "print(f\"内容：{docs_chunks[0].page_content}\")\n",
    "print(f\"来源标题：{docs_chunks[0].metadata['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8cea82",
   "metadata": {},
   "source": [
    "**运行结果示例**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac7306",
   "metadata": {
    "attributes": {
     "classes": [
      "text"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "原始文档数量：100\n",
    "分块后片段数量：248\n",
    "第一个片段示例：\n",
    "内容：阿尔伯特·爱因斯坦（德语：Albert Einstein，1879 年 3 月 14 日－1955 年 4 月 18 日），犹太裔理论物理学家，创立了狭义相对论和广义相对论，被公认为是现代物理学之父。他的质能方程 E=mc²是物理学中最著名的方程之一，对原子弹的发展有重要影响。1921 年，爱因斯坦因光电效应获得诺贝尔物理学奖。\n",
    "来源标题：阿尔伯特·爱因斯坦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9322cc8",
   "metadata": {},
   "source": [
    "### 1.4 加载编码模型\n",
    "\n",
    "AI 无法直接“理解”文字，需要把文本转换成数字向量（叫“embedding”）——就像给每个文本片段发一个“身份证号”，相似的文本“身份证号”更接近。我们用中文优化的公开模型`chuxin-llm/Chuxin-Embedding`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragflow.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# 加载中文文本编码模型（在线下载，首次运行需 1-2 分钟）\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"chuxin-llm/Chuxin-Embedding\",  # 模型名称（公开可查）\n",
    "    model_kwargs={\"device\": \"auto\"},  # 自动适配 CPU/GPU（有 GPU 会更快）\n",
    "    encode_kwargs={\"normalize_embeddings\": True}  # 向量归一化（让相似度计算更准确）\n",
    ")\n",
    "\n",
    "# 验证：给一句话编码，查看向量维度\n",
    "test_text = \"爱因斯坦是物理学家\"\n",
    "test_vector = embedding_model.embed_query(test_text)\n",
    "print(f\"文本编码后的向量维度：{len(test_vector)}\")  # 输出 1024（模型固定输出维度）\n",
    "print(f\"向量前 5 个数值：{test_vector[:5]}\")  # 示例：[-0.02, 0.05, -0.01, 0.03, -0.04]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6a7ae7",
   "metadata": {},
   "source": [
    "### 1.5 构建向量数据库\n",
    "\n",
    "把所有分块的向量存到数据库（用 FAISS，轻量级且速度快），后续查问题时，能快速找到相似的文本片段："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragflow.vectorstores import FAISS\n",
    "\n",
    "# 1. 构建向量数据库（把分块文本和对应的向量关联起来）\n",
    "vector_db = FAISS.from_documents(\n",
    "    documents=docs_chunks,  # 分块后的文本片段\n",
    "    embedding=embedding_model  # 刚才加载的编码模型\n",
    ")\n",
    "\n",
    "# 2. 保存数据库到本地（可选，下次运行不用重新构建，节省时间）\n",
    "vector_db.save_local(\"wiki_vector_db\")\n",
    "print(\"向量数据库已保存到本地文件夹：wiki_vector_db\")\n",
    "\n",
    "# 3. 加载本地数据库（下次运行时，直接用这行代码替代上面的“构建”步骤）\n",
    "# vector_db = FAISS.load_local(\n",
    "#     \"wiki_vector_db\",\n",
    "#     embedding=embedding_model,\n",
    "#     allow_dangerous_deserialization=True  # 自己生成的数据库安全，放心开启\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac20323",
   "metadata": {},
   "source": [
    "### 1.6 创建检索器\n",
    "\n",
    "检索器的作用是：输入一个问题，它会从向量数据库中找出最相似的文本片段。我们设置“返回 3 条最相关的片段”，并过滤掉太不相关的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d1bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建检索器\n",
    "retriever = vector_db.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 3,  # 每次检索返回 3 条最相似的片段\n",
    "        \"score_threshold\": 0.6  # 过滤相似度低于 0.6 的片段（避免无关信息干扰）\n",
    "    }\n",
    ")\n",
    "\n",
    "# 测试检索：问一个问题，看能否找到相关文档\n",
    "test_query = \"爱因斯坦获得过什么奖项？\"\n",
    "retrieved_docs = retriever.invoke(test_query)\n",
    "\n",
    "# 打印检索结果\n",
    "print(f\"针对问题「{test_query}」，找到{len(retrieved_docs)}条相关文档：\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"\\n 第{i}条：\")\n",
    "    print(f\"来源标题：{doc.metadata['title']}\")\n",
    "    print(f\"相关内容：{doc.page_content}\")\n",
    "    print(f\"相似度得分：{round(doc._score, 3)}\")  # 得分越低，相似度越高（0 最像，2 最不像）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be3dfb",
   "metadata": {},
   "source": [
    "**运行结果示例**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2becf489",
   "metadata": {
    "attributes": {
     "classes": [
      "text"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "针对问题「爱因斯坦获得过什么奖项？」，找到 1 条相关文档：\n",
    "\n",
    "第 1 条：\n",
    "来源标题：阿尔伯特·爱因斯坦\n",
    "相关内容：阿尔伯特·爱因斯坦（德语：Albert Einstein，1879 年 3 月 14 日－1955 年 4 月 18 日），犹太裔理论物理学家，创立了狭义相对论和广义相对论，被公认为是现代物理学之父。他的质能方程 E=mc²是物理学中最著名的方程之一，对原子弹的发展有重要影响。1921 年，爱因斯坦因光电效应获得诺贝尔物理学奖。\n",
    "相似度得分：0.321"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83165e4",
   "metadata": {},
   "source": [
    "## 2. 文本生成\n",
    "\n",
    "### 2.1 加载生成模型\n",
    "\n",
    "我们用轻量级的中文生成模型`Qwen/Qwen-1.8B-Chat`（在线下载，普通电脑也能跑），它会基于检索到的文档片段，生成自然语言回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d341114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from ragflow.llms import HuggingFacePipeline\n",
    "\n",
    "# 1. 加载中文生成模型（首次运行需下载，约 3.6GB）\n",
    "model_name = \"Qwen/Qwen-1.8B-Chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True  # 加载模型的自定义代码（中文模型必需）\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",  # 自动适配数据类型（减少内存占用）\n",
    "    device_map=\"auto\",   # 自动分配 CPU/GPU\n",
    "    trust_remote_code=True\n",
    ").eval()  # 切换为“评估模式”（禁用训练功能，更快更稳定）\n",
    "\n",
    "# 2. 创建文本生成管道（控制生成效果的参数）\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=300,  # 回答最多 300 字（避免太长）\n",
    "    temperature=0.7,     # 0-1 之间：越低回答越“严谨”，越高越“灵活”（0.7 适合事实问答）\n",
    "    top_p=0.9,           # 只从概率前 90%的词中选（避免生僻词）\n",
    "    pad_token_id=tokenizer.eos_token_id  # 修复中文生成的“换行 bug”\n",
    ")\n",
    "\n",
    "# 3. 包装为 RAGFlow 的 LLM 接口（让生成模型能和检索器配合）\n",
    "llm = HuggingFacePipeline(pipeline=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54348aa",
   "metadata": {},
   "source": [
    "### 2.2 定义提示词模板\n",
    "\n",
    "给 AI 一个“答题规则”：只能用检索到的文档内容回答，不知道就说“无法回答”，不要瞎编。用中文写模板，简单易懂："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragflow.prompts import PromptTemplate\n",
    "\n",
    "# 中文提示词模板\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"请严格按照以下规则回答用户问题：\n",
    "1. 只能使用提供的【相关文档内容】中的信息，不能用其他外部知识；\n",
    "2. 如果文档中没有相关信息，直接回答“根据提供的资料，无法回答该问题”；\n",
    "3. 回答要简洁、准确，用中文口语化表达，不要用专业术语堆砌。\n",
    "\n",
    "【相关文档内容】\n",
    "{context}\n",
    "\n",
    "【用户问题】\n",
    "{question}\n",
    "\n",
    "【回答】\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]  # 两个变量：检索到的“内容”和用户“问题”\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec132461",
   "metadata": {},
   "source": [
    "### 2.3 构建问答链 QA\n",
    "\n",
    "用 RAGFlow 的`RetrievalQA`工具，把检索器、生成模型、提示词模板整合起来，形成完整的 RAG 问答链："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragflow.chains import RetrievalQA\n",
    "\n",
    "# 构建问答链\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,  # 生成模型\n",
    "    chain_type=\"stuff\",  # 简单模式：把所有检索到的内容拼起来给模型（适合初学者）\n",
    "    retriever=retriever,  # 检索器\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": prompt_template,  # 传入提示词模板\n",
    "        \"document_separator\": \"\\n\\n---\\n\\n\"  # 分隔多个检索结果（让模型看得更清楚）\n",
    "    },\n",
    "    return_source_documents=True  # 回答时返回用到的源文档（方便验证）\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a9b85c",
   "metadata": {},
   "source": [
    "### 2.4 测试问答系统 QA\n",
    "\n",
    "现在可以向系统提问了！我们测试 2 个问题，看看效果：\n",
    "\n",
    "1. 测试 1：有相关文档的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提问 1：有明确答案的问题\n",
    "query1 = \"爱因斯坦是因为什么成就获得诺贝尔物理学奖的？\"\n",
    "result1 = qa_chain.invoke(query1)\n",
    "\n",
    "# 打印结果\n",
    "print(\"【问题 1】\", query1)\n",
    "print(\"【回答】\", result1[\"result\"])\n",
    "print(\"\\n【用到的源文档】\")\n",
    "for doc in result1[\"source_documents\"]:\n",
    "    print(f\"- 标题：{doc.metadata['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9814982",
   "metadata": {},
   "source": [
    "**运行结果示例**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab2b0e",
   "metadata": {
    "attributes": {
     "classes": [
      "text"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "【问题 1】 爱因斯坦是因为什么成就获得诺贝尔物理学奖的？\n",
    "【回答】 爱因斯坦是因为光电效应这一成就获得诺贝尔物理学奖的，获奖时间是 1921 年。\n",
    "\n",
    "【用到的源文档】\n",
    "- 标题：阿尔伯特·爱因斯坦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b736439",
   "metadata": {},
   "source": [
    "2. 测试 2：无相关文档的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e9809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提问 2：数据集中没有的问题\n",
    "query2 = \"量子计算机是什么时候发明的？\"\n",
    "result2 = qa_chain.invoke(query2)\n",
    "\n",
    "print(\"\\n【问题 2】\", query2)\n",
    "print(\"【回答】\", result2[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f76c61",
   "metadata": {},
   "source": [
    "**运行结果示例**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa50cca",
   "metadata": {
    "attributes": {
     "classes": [
      "text"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "【问题 2】 量子计算机是什么时候发明的？\n",
    "【回答】 根据提供的资料，无法回答该问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e4fb1b",
   "metadata": {},
   "source": [
    "## 3. 总结\n",
    "\n",
    "本实验用最简单的步骤，实现了一个完整的 RAG 问答系统：从加载公开数据，到文本分块、向量数据库构建，再到检索+生成联动。初学者可以基于这个框架，尝试替换其他数据集（比如自己的 PDF 文档）或模型，逐步探索 RAG 的更多用法！"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
