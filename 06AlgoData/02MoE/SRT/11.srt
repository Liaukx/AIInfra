1
00:00:00,000 --> 00:00:02,000
内容/录制:Z0MI 酱，视频剪辑/字幕:梁嘉铭

2
00:00:02,533 --> 00:00:03,933
大家好我是那个更完

3
00:00:03,933 --> 00:00:06,433
这一期就不怎么再更新了 ZOMI 了

4
00:00:06,433 --> 00:00:07,566
后面的可能会半年后

5
00:00:07,600 --> 00:00:09,366
或者甚至一年后再更新了

6
00:00:13,600 --> 00:00:14,233
那现在

7
00:00:14,233 --> 00:00:15,900
我们今天的内容比较特殊

8
00:00:15,933 --> 00:00:17,433
使用昇腾的服务器

9
00:00:17,433 --> 00:00:19,766
去手撕一个 moe 的代码

10
00:00:20,066 --> 00:00:21,333
那在整一期视频里面

11
00:00:21,366 --> 00:00:23,633
可能我们会分开几个小节

12
00:00:23,633 --> 00:00:25,666
第一个我们使用单机 8 卡

13
00:00:25,666 --> 00:00:26,833
应该是单机单卡

14
00:00:26,833 --> 00:00:29,033
去实现一个 MOE 的代码

15
00:00:29,233 --> 00:00:30,433
既然有单机单卡了

16
00:00:30,433 --> 00:00:31,266
我们肯定不满足

17
00:00:31,266 --> 00:00:32,066
因为 Moe

18
00:00:32,066 --> 00:00:33,266
每一个专家

19
00:00:33,266 --> 00:00:35,333
是占用一张卡的时候怎么办

20
00:00:35,366 --> 00:00:35,666
于是

21
00:00:35,666 --> 00:00:38,700
我们就实现了一个单机 8 卡的 Moe

22
00:00:39,000 --> 00:00:40,933
每一张卡放一个 MoE 的模型

23
00:00:40,933 --> 00:00:42,766
或者放一个 MoE 的专家进去

24
00:00:42,766 --> 00:00:43,966
那有了单机单卡

25
00:00:43,966 --> 00:00:45,333
跟单机 8 卡的内容之后

26
00:00:45,333 --> 00:00:47,200
我们就后面就重点

27
00:00:47,200 --> 00:00:48,633
使用一个 Profiling 的工具了

28
00:00:48,633 --> 00:00:50,533
也就真正的去打开看一下

29
00:00:50,566 --> 00:00:53,833
MoE 的计算跟通讯的耗时的占比

30
00:00:53,966 --> 00:00:56,400
使用昇腾的 xxx studio 的工具

31
00:00:56,400 --> 00:00:57,966
不管你用 mass studio 也好

32
00:00:57,966 --> 00:00:59,733
还是使用 NV inside 也好

33
00:00:59,733 --> 00:01:01,000
其实都是类似的

34
00:01:01,233 --> 00:01:02,866
那在整个视频的目录大纲了

35
00:01:02,866 --> 00:01:04,933
我们现在已经来到了快接近尾声了

36
00:01:04,966 --> 00:01:06,833
手撕一个 MoE 的代码

37
00:01:06,833 --> 00:01:07,766
那后面的内容

38
00:01:07,800 --> 00:01:09,533
ZOMI 觉得可能过于的深了

39
00:01:09,533 --> 00:01:11,933
所以就不在这里面去跟大家去展开

40
00:01:12,233 --> 00:01:13,866
可能会在工作当中

41
00:01:13,866 --> 00:01:15,233
大家会更多的用到

42
00:01:15,233 --> 00:01:18,033
我们现在还是做一个简单的实现哦

43
00:01:18,066 --> 00:01:19,833
那这里面很多的东西

44
00:01:19,833 --> 00:01:22,466
主要还是欢迎大家去回看一下

45
00:01:22,466 --> 00:01:24,266
MoE 的一个架构的原理

46
00:01:24,266 --> 00:01:25,866
因为今天所有实现的代码

47
00:01:25,866 --> 00:01:27,900
都是从 MoE 架构的原理里面

48
00:01:27,933 --> 00:01:28,633
去真正的

49
00:01:28,633 --> 00:01:29,700
实现出来的

50
00:01:29,733 --> 00:01:31,266
那今天我们事不宜迟

51
00:01:31,666 --> 00:01:33,133
马上去到第一个内容

52
00:01:33,166 --> 00:01:34,433
去看一下单机单卡

53
00:01:34,433 --> 00:01:37,266
也就是单卡版本的 Moe 的实现

54
00:01:37,766 --> 00:01:39,800
我们现在来打开 Python 了跟 ZOMI

55
00:01:39,800 --> 00:01:41,766
一起手撕一个具体的代码

56
00:01:41,766 --> 00:01:43,866
首先我们 import touch

57
00:01:43,866 --> 00:01:46,700
那这里面代码可能会快进 1.5 倍

58
00:01:46,733 --> 00:01:48,333
甚至两三倍的速度

59
00:01:48,333 --> 00:01:49,733
去跟大家去展示的

60
00:01:49,733 --> 00:01:52,200
首先我们加载一些正常的东西

61
00:01:55,466 --> 00:01:55,966
那接着

62
00:01:56,000 --> 00:01:58,366
我们现在加载了正常的东西之后

63
00:01:58,366 --> 00:02:01,133
我们开始来实现一个具体的专家了

64
00:02:01,333 --> 00:02:03,133
那所谓的专家

65
00:02:03,666 --> 00:02:05,366
在之前的一个内容里面

66
00:02:05,400 --> 00:02:06,366
跟大家分享过

67
00:02:06,366 --> 00:02:09,866
其实它是一个简单的小的神经网络

68
00:02:09,933 --> 00:02:11,166
先把模型的层

69
00:02:11,166 --> 00:02:13,333
就用一个 Linear 的层变小

70
00:02:13,333 --> 00:02:15,066
然后变大再变小这么一个过程

71
00:02:15,066 --> 00:02:17,533
我们现在通过代码来去跟大家实现

72
00:02:20,866 --> 00:02:23,066
input DIM 输入的大小

73
00:02:25,666 --> 00:02:26,466
那可以看到了

74
00:02:26,466 --> 00:02:28,233
我们的一个函数的输入

75
00:02:28,233 --> 00:02:28,833
有 input DIM

76
00:02:28,833 --> 00:02:30,300
hidden DIM 还有 output DIM

77
00:02:30,333 --> 00:02:32,866
分别对应我们简单的一个小网络的

78
00:02:32,866 --> 00:02:34,366
不同的一个 size

79
00:02:39,600 --> 00:02:42,233
那我们现在来到了第一个层

80
00:02:42,233 --> 00:02:43,766
用 Linear 层来去实现

81
00:02:43,800 --> 00:02:45,166
有一个 input dim

82
00:02:45,833 --> 00:02:47,733
然后也有一个 hit dim

83
00:02:50,833 --> 00:02:54,033
接着来加一个简单的 GELU 的激活

84
00:02:54,933 --> 00:02:58,866
然后最后再套一个简单的神经网络

85
00:03:01,833 --> 00:03:03,700
这样我们就实现了整个专家的定义

86
00:03:03,733 --> 00:03:06,400
然后真正的执行是 def

87
00:03:10,000 --> 00:03:11,833
那整个专家已经定义好了

88
00:03:11,833 --> 00:03:13,433
我们现在来真正的实现

89
00:03:13,433 --> 00:03:15,500
整个 moe 的类了

90
00:03:15,533 --> 00:03:17,533
也就是整个大的网络模型

91
00:03:17,866 --> 00:03:19,433
我们现在所实现的内容

92
00:03:19,433 --> 00:03:21,333
是不在 Transformer 加工里面的

93
00:03:21,366 --> 00:03:23,933
只是简单的做一个 moe 的事例

94
00:03:23,933 --> 00:03:25,033
是我们会有很多

95
00:03:25,033 --> 00:03:28,066
个专家通过一个整个大的 moe 的类

96
00:03:28,066 --> 00:03:30,566
来去把我们刚才的 moe 的一个 Expert

97
00:03:30,766 --> 00:03:32,166
然后把它套起来

98
00:03:43,566 --> 00:03:44,000
那这里面

99
00:03:44,000 --> 00:03:45,566
我们可以看到从入参里面

100
00:03:45,566 --> 00:03:46,433
我们有 input dim

101
00:03:46,433 --> 00:03:47,833
有那个专家的数量

102
00:03:47,833 --> 00:03:49,900
然后有 Top-K 的一个参数

103
00:03:49,933 --> 00:03:51,033
也就是我们对应的超参

104
00:03:51,033 --> 00:03:52,766
还有我们的一个专家的容量

105
00:03:52,800 --> 00:03:53,600
还有 hidden dim

106
00:03:53,600 --> 00:03:54,966
还有对应的 output dim

107
00:03:54,966 --> 00:03:55,466
那接着

108
00:03:55,466 --> 00:03:58,066
我们对下面的几个词进行一个赋能

109
00:04:03,166 --> 00:04:04,433
那有了这些赋能之后

110
00:04:04,433 --> 00:04:06,466
我们现在来到了一个真正实现

111
00:04:06,466 --> 00:04:07,766
路由网络了

112
00:04:09,600 --> 00:04:11,200
其实我们在之前的内容里面

113
00:04:11,200 --> 00:04:12,533
去实现了一个路由网络

114
00:04:12,533 --> 00:04:13,066
实际上

115
00:04:13,066 --> 00:04:15,633
路由网络是由两个模型层去组成的

116
00:04:15,633 --> 00:04:16,700
一层是线性层

117
00:04:16,733 --> 00:04:18,166
一层是 softmas 层

118
00:04:18,833 --> 00:04:19,233
对应的

119
00:04:19,233 --> 00:04:21,300
在之前的一个可视化 PPT 里面

120
00:04:21,333 --> 00:04:22,833
我们看到整个路由

121
00:04:22,833 --> 00:04:24,666
实际上是由一个 FFN 层

122
00:04:24,666 --> 00:04:26,700
也就是我们刚才实现的 Linear 层

123
00:04:26,800 --> 00:04:28,233
跟一个 Softmax 来组成

124
00:04:28,233 --> 00:04:29,866
那所以说我们现在代码

125
00:04:29,866 --> 00:04:31,466
也是这么去设计的

126
00:04:31,466 --> 00:04:32,666
那我们的一个 gat

127
00:04:32,666 --> 00:04:34,100
就是我们的所谓的路由

128
00:04:34,133 --> 00:04:34,633
那现在

129
00:04:34,633 --> 00:04:36,666
我们来实现一个专家的集合

130
00:04:41,633 --> 00:04:42,866
那有了专家之后

131
00:04:42,866 --> 00:04:44,033
实际上专家这里面

132
00:04:44,033 --> 00:04:46,033
是调用上面的专家的实现的

133
00:04:46,033 --> 00:04:48,833
那现在是 for in range

134
00:04:48,833 --> 00:04:49,900
然后 self experts

135
00:04:49,933 --> 00:04:50,600
那这里面

136
00:04:50,600 --> 00:04:53,333
就证明了我们到底有多少个 experts

137
00:04:53,333 --> 00:04:54,200
如果有 8 个 experts

138
00:04:54,200 --> 00:04:56,133
那我们就每举八个出来

139
00:04:56,533 --> 00:04:58,000
那有了相关的定义之后

140
00:04:58,000 --> 00:04:58,566
我们现在

141
00:04:58,566 --> 00:05:01,433
就真正的去我们的执行的代码

142
00:05:01,600 --> 00:05:03,000
self def forward

143
00:05:06,833 --> 00:05:07,466
有了 device

144
00:05:07,466 --> 00:05:09,433
是声明我们的一个具体的代码

145
00:05:09,433 --> 00:05:10,466
哦那我们现在

146
00:05:10,466 --> 00:05:12,900
才真正的去实现我们路由的内容

147
00:05:12,933 --> 00:05:16,366
logist 等于 self gate

148
00:05:17,133 --> 00:05:19,533
把上面的 gate 做一个实体化的然

149
00:05:19,533 --> 00:05:22,166
后我们现在要算一个 probabilities

150
00:05:22,166 --> 00:05:23,433
也就是对应的概率

151
00:05:23,633 --> 00:05:26,533
对应的概率是用 Softmax 来去实现的

152
00:05:30,666 --> 00:05:33,633
Softmax 之后我们现在去算一个 Top-K

153
00:05:37,933 --> 00:05:38,466
刷完 Top-K

154
00:05:38,466 --> 00:05:40,066
之后我们现在

155
00:05:40,066 --> 00:05:41,966
还没有到那个辅助损失函数

156
00:05:42,000 --> 00:05:43,166
我们现在算完 Top-K

157
00:05:43,166 --> 00:05:43,433
之后

158
00:05:43,433 --> 00:05:47,100
我们来到了一个所谓的专家分配了

159
00:05:53,666 --> 00:05:54,366
那这里面

160
00:05:54,400 --> 00:05:56,633
主要是专家分配的逻辑分别

161
00:05:56,633 --> 00:05:58,500
得到一个一维的专家的索引

162
00:05:58,533 --> 00:06:00,866
和对应的一个分配的概率

163
00:06:01,000 --> 00:06:01,466
那接着

164
00:06:01,466 --> 00:06:02,666
我们现在要实现一个

165
00:06:02,666 --> 00:06:05,300
生成一个跟 Betch 大小相同的一个 Top-K

166
00:06:05,333 --> 00:06:06,866
相关的一个样本索引

167
00:06:10,366 --> 00:06:11,833
有了对应的一个

168
00:06:11,866 --> 00:06:14,300
每一个 Top-K 的专家项目的索引

169
00:06:14,333 --> 00:06:16,366
我们现在要对专家的索引的概率

170
00:06:16,366 --> 00:06:16,966
一一对应

171
00:06:16,966 --> 00:06:18,666
这样就能够知道每个样本

172
00:06:18,666 --> 00:06:19,900
被分配到哪个专家

173
00:06:19,933 --> 00:06:21,566
以及对应的权重了

174
00:06:25,833 --> 00:06:26,133
那这个

175
00:06:26,166 --> 00:06:28,600
我们就完成了整个专家的分配

176
00:06:28,600 --> 00:06:29,866
那有兴趣的小伙伴们

177
00:06:29,866 --> 00:06:32,533
也可以 print 出来对应的一个 ship 大小

178
00:06:32,566 --> 00:06:35,600
然后我们现在来到一个初始化了

179
00:06:35,600 --> 00:06:37,800
输出的初始化 outputs 等于

180
00:06:42,466 --> 00:06:44,033
对输出进行一个初始化

181
00:06:44,033 --> 00:06:45,933
之后现在迭代每一个专家

182
00:06:45,966 --> 00:06:46,800
对每一个专家

183
00:06:46,800 --> 00:06:48,766
进行一个处理和计算的

184
00:06:50,766 --> 00:06:51,566
有多少个专家

185
00:06:51,566 --> 00:06:52,933
那假设我们现在有 8 个专家

186
00:06:52,933 --> 00:06:53,733
那每个专家

187
00:06:53,733 --> 00:06:55,933
都需要独立的去进行一个迭代

188
00:06:56,666 --> 00:06:58,033
那下面我们需要一个获取

189
00:06:58,033 --> 00:06:59,700
分配给当前专家的样本

190
00:06:59,733 --> 00:07:01,200
也就获取对应的样本了

191
00:07:01,200 --> 00:07:03,366
然后每一个 batch

192
00:07:03,366 --> 00:07:05,233
都会有一个对应的值

193
00:07:05,233 --> 00:07:06,666
或者对应的一个 index

194
00:07:06,866 --> 00:07:08,933
其中下面这一个一系列的

195
00:07:08,966 --> 00:07:10,633
所以表示为 xxxx 的位置

196
00:07:10,633 --> 00:07:15,066
就代表该样本被分配到当前的专家

197
00:07:15,333 --> 00:07:16,766
所以我们有一个 mask

198
00:07:20,633 --> 00:07:22,366
有了对应的 expert Mask 之后

199
00:07:22,400 --> 00:07:23,766
我们根据 expert Mask

200
00:07:23,766 --> 00:07:26,766
筛选出分配给当前专家的样本和索引

201
00:07:26,766 --> 00:07:28,266
对应的权重

202
00:07:28,266 --> 00:07:30,933
所以我们有一个 expert simple 跟 expert weights

203
00:07:32,866 --> 00:07:35,866
还有 expert weights

204
00:07:36,766 --> 00:07:39,466
分配对应的一个专家的权重

205
00:07:39,533 --> 00:07:42,733
flat probs 然后也是 expert Mask

206
00:07:42,866 --> 00:07:43,633
然后下面

207
00:07:43,633 --> 00:07:46,033
我们进行一个容量的限制了

208
00:07:46,966 --> 00:07:49,966
就是对应的去对每一个专家的输入

209
00:07:49,966 --> 00:07:53,533
控制他输给这个专家的 batch 的大小

210
00:07:53,533 --> 00:07:54,833
或者我们输入到这个

211
00:07:54,833 --> 00:07:57,300
这个专家的一个 TOKEN 的数量

212
00:08:07,233 --> 00:08:08,966
对专家进行一个流量控制

213
00:08:09,000 --> 00:08:09,233
之后

214
00:08:09,233 --> 00:08:11,233
我们现在来开始处理每一个专家

215
00:08:11,233 --> 00:08:12,733
每一个专家的真正计算的

216
00:08:12,766 --> 00:08:15,366
才在这里面的 asput input

217
00:08:17,600 --> 00:08:18,400
expert 的

218
00:08:20,166 --> 00:08:21,633
expert 的 simple

219
00:08:21,633 --> 00:08:23,166
把我们刚才讲到的

220
00:08:23,200 --> 00:08:24,466
每一个 expert 的 simple

221
00:08:24,466 --> 00:08:27,266
给到我们的最开始的 forward 的输入

222
00:08:27,366 --> 00:08:30,366
然后就是我们整个 expert 的输入了

223
00:08:30,366 --> 00:08:32,333
然后 expert 的 output

224
00:08:35,666 --> 00:08:39,700
将输入的数据传给我们当前的专家 expert

225
00:08:39,700 --> 00:08:41,033
当前的专家定义

226
00:08:41,066 --> 00:08:42,333
就是我们刚才讲到的

227
00:08:42,366 --> 00:08:44,866
我们定义了这个 expert 的实例化的对象

228
00:08:44,866 --> 00:08:46,433
那这个 expert 的实例化的对象

229
00:08:46,433 --> 00:08:47,433
就在这里面

230
00:08:47,466 --> 00:08:49,900
expert 那我们现在

231
00:08:49,933 --> 00:08:51,666
已经对整个专家实例化

232
00:08:51,666 --> 00:08:54,266
就得到我们当前专家的输入

233
00:08:54,266 --> 00:08:56,533
然后我们将当前专家的数

234
00:08:56,566 --> 00:08:59,166
跟对应的权重哦进行相乘

235
00:09:04,966 --> 00:09:06,133
exper 的 output

236
00:09:06,133 --> 00:09:09,866
然后去乘以我们的 exper 的 weight

237
00:09:11,566 --> 00:09:11,866
这样

238
00:09:11,866 --> 00:09:14,233
我们就得到了整体的专家的输出

239
00:09:14,233 --> 00:09:16,466
但是现在我们有很多个专家

240
00:09:16,466 --> 00:09:17,866
因为我们在 for 里面

241
00:09:18,866 --> 00:09:19,366
所以

242
00:09:19,400 --> 00:09:22,000
我们需要进行一个累加输出的

243
00:09:22,766 --> 00:09:24,833
也就是对应之前的一个 keep Top-K

244
00:09:24,833 --> 00:09:26,700
我们选择了 Top-K 个 expert

245
00:09:26,733 --> 00:09:28,933
之后对每一个 expert 的输出

246
00:09:28,933 --> 00:09:31,166
进行一个累加 aggregation

247
00:09:31,600 --> 00:09:33,066
那我们现在回到代码里面

248
00:09:33,066 --> 00:09:34,433
看一下累加怎么实现

249
00:09:37,266 --> 00:09:41,133
把整个 expert 的 weight 的 output 进行一个累加

250
00:09:41,200 --> 00:09:43,033
完成将各个专家的输出

251
00:09:43,033 --> 00:09:45,433
汇总到最终的一个输出结果里面

252
00:09:45,433 --> 00:09:47,066
然后进行一个 return

253
00:09:49,233 --> 00:09:49,633
return

254
00:09:49,633 --> 00:09:55,466
我们的 output 跟我们的还还有一个 loss

255
00:09:55,466 --> 00:09:56,133
哦嗯

256
00:09:56,166 --> 00:09:57,166
这里面哦

257
00:09:57,166 --> 00:09:58,533
怪不得标黄了

258
00:09:58,533 --> 00:10:00,233
因为我们的代码写错了

259
00:10:00,266 --> 00:10:02,333
那我们还有一个 loss 是没有实现的

260
00:10:02,366 --> 00:10:04,366
于是我们现在来去实现一个

261
00:10:04,366 --> 00:10:06,800
对应的一个辅助损失函数

262
00:10:07,000 --> 00:10:08,366
那在辅助损失函数

263
00:10:08,366 --> 00:10:11,800
主要是在 for 之前进行一个定义

264
00:10:11,800 --> 00:10:13,400
或者我们在这个位置

265
00:10:13,400 --> 00:10:15,266
在我们的 keep Top-K 之后

266
00:10:15,333 --> 00:10:17,200
我们定义我们的辅助函数

267
00:10:17,200 --> 00:10:19,200
那如果我们是在训练的阶段

268
00:10:19,200 --> 00:10:22,066
需要有一个损失函数的定义的

269
00:10:22,066 --> 00:10:24,166
所以是放在 self training 里面

270
00:10:24,733 --> 00:10:25,166
那现在

271
00:10:25,166 --> 00:10:27,466
我们主要是对整个重要性的损失

272
00:10:27,466 --> 00:10:30,666
也就是专家的一个均衡负载的内容

273
00:10:30,800 --> 00:10:32,066
接着我们首先

274
00:10:32,066 --> 00:10:34,833
要实现一个重要性的损失

275
00:10:36,000 --> 00:10:37,600
那所谓的重要性的损失

276
00:10:37,600 --> 00:10:38,400
其实之前

277
00:10:38,400 --> 00:10:39,633
钟敏跟大家介绍过

278
00:10:39,633 --> 00:10:43,466
我们主要是算一个 coefficient 的一个 Variation

279
00:10:43,566 --> 00:10:45,533
把每一个数的样本的

280
00:10:45,533 --> 00:10:46,833
一个具体的容量

281
00:10:46,833 --> 00:10:48,033
把它都计算出来

282
00:10:48,033 --> 00:10:50,500
然后进行一个均衡负载然以后

283
00:10:50,533 --> 00:10:52,133
这个变异系数的

284
00:11:02,600 --> 00:11:04,433
我们刚才算完一个重要性损失之后

285
00:11:04,433 --> 00:11:05,066
我们现在

286
00:11:05,066 --> 00:11:07,233
来去计算一个负载均衡的损失

287
00:11:07,233 --> 00:11:09,233
也就是 load balance loss

288
00:11:31,200 --> 00:11:32,766
那有了两个 loss 之后

289
00:11:32,766 --> 00:11:34,400
我们现在的辅助损失函数

290
00:11:34,400 --> 00:11:37,066
是把两个 loss 进行一个加起来

291
00:11:38,000 --> 00:11:39,200
如果不是训练

292
00:11:39,200 --> 00:11:40,600
就是我们推理的过程

293
00:11:40,600 --> 00:11:43,133
那我们还需要是一个 Asteri loss

294
00:11:43,133 --> 00:11:46,600
等于进行一个输出的

295
00:11:46,600 --> 00:11:47,166
那基本上

296
00:11:47,166 --> 00:11:49,766
我们现在完成了整个代码的内容了

297
00:11:49,766 --> 00:11:52,433
你如果对这个代码有兴趣的小伙伴

298
00:11:52,800 --> 00:11:54,166
也可以去到 ZOMI 的

299
00:11:54,166 --> 00:11:56,000
这个 AI infar 相关的内容

300
00:11:56,000 --> 00:11:56,800
这里面的代码

301
00:11:56,800 --> 00:12:01,000
放在 AIgoData 里面的这个 MoE

302
00:12:01,133 --> 00:12:02,233
然后在 MoE 里面

303
00:12:02,233 --> 00:12:03,833
这里面 ZOMI 会更新一个 code

304
00:12:03,833 --> 00:12:05,666
然后方便大家去学习的

305
00:12:05,666 --> 00:12:06,566
那基本上的内容

306
00:12:06,600 --> 00:12:07,933
ZOMI 都会放在这里面

307
00:12:07,933 --> 00:12:10,466
所有的 PPT 跟视频都会一一对应

308
00:12:10,466 --> 00:12:11,133
那我们现在

309
00:12:11,166 --> 00:12:14,600
还是回到对应的代码

310
00:12:14,833 --> 00:12:16,833
我们要完成整体的一个示例

311
00:12:16,833 --> 00:12:20,366
所以需要建立一个 main 的函数

312
00:12:20,400 --> 00:12:22,833
然后把我们刚才的 input dim

313
00:12:22,833 --> 00:12:23,966
这些都定义好

314
00:12:24,000 --> 00:12:26,433
就我们的一些对应的超参

315
00:12:26,466 --> 00:12:28,300
那 input dim 是 128

316
00:12:28,333 --> 00:12:29,833
然后我们有一个 output dim

317
00:12:29,833 --> 00:12:31,466
等于 256

318
00:12:31,466 --> 00:12:33,900
所以我们整个专家的 input 跟 output

319
00:12:33,933 --> 00:12:35,133
是非常的清楚的

320
00:12:35,133 --> 00:12:35,833
有了这个了

321
00:12:35,833 --> 00:12:37,866
我们看一下中间的 hidden dim

322
00:12:37,966 --> 00:12:38,533
hidden dim 

323
00:12:38,533 --> 00:12:39,000
蛮有意思的

324
00:12:39,000 --> 00:12:41,333
就肯定要要比 input dim 跟 output dim 要大

325
00:12:41,333 --> 00:12:42,800
所以我们是一个 512

326
00:12:43,066 --> 00:12:44,733
那整体的专家的数量

327
00:12:44,766 --> 00:12:48,066
我们去定义是 8 个 expertr 等于 8

328
00:12:48,066 --> 00:12:50,266
因为在单机单卡或者单机 8 卡

329
00:12:50,266 --> 00:12:51,966
我们都会设计 8 个专家

330
00:12:52,000 --> 00:12:52,833
看一下这 8 个专

331
00:12:52,833 --> 00:12:54,166
家是怎么去实现的

332
00:12:54,200 --> 00:12:55,466
然后 keep Top-K

333
00:12:55,466 --> 00:12:57,633
是 2 选择其中两个专家

334
00:12:57,633 --> 00:12:59,966
进行实际的一个运算

335
00:13:00,000 --> 00:13:04,366
那 expert 的 capacity 等于 32

336
00:13:04,366 --> 00:13:05,933
那 expert 的 capacity 等于 32

337
00:13:05,933 --> 00:13:07,333
也就是每一个专家

338
00:13:07,333 --> 00:13:09,566
最大的接受的 simple 的容量

339
00:13:09,566 --> 00:13:11,666
是 32 那这个时候

340
00:13:11,666 --> 00:13:12,966
我们的 batch size

341
00:13:13,000 --> 00:13:14,766
就要比这个 32 要大

342
00:13:14,766 --> 00:13:16,633
而且我们有两个专家

343
00:13:16,633 --> 00:13:18,333
最少选择 Top-K 两个

344
00:13:18,366 --> 00:13:19,066
所以这里面

345
00:13:19,066 --> 00:13:20,233
我们的 batch size

346
00:13:20,233 --> 00:13:23,766
就设定为整个 expert 的 capacity 的两倍

347
00:13:24,833 --> 00:13:25,833
等于 64

348
00:13:27,066 --> 00:13:28,566
那有了相关的定义之后

349
00:13:28,600 --> 00:13:30,866
我们现在来看看 X=touch

350
00:13:31,000 --> 00:13:33,600
哦因为我们是在整个 NPU 去实现的

351
00:13:33,600 --> 00:13:34,366
所以这里面

352
00:13:34,366 --> 00:13:42,600
漏了 import touch-NPU

353
00:13:43,166 --> 00:13:43,633
这样的话

354
00:13:43,633 --> 00:13:44,366
我们的代码

355
00:13:44,400 --> 00:13:46,200
才能够在昇腾的 NPU 上面

356
00:13:46,200 --> 00:13:47,866
能够再去执行的

357
00:13:47,933 --> 00:13:48,600
那没关系

358
00:13:48,600 --> 00:13:49,833
我们刚才只是漏了

359
00:13:49,833 --> 00:13:51,433
我们现在来继续往下看

360
00:13:52,333 --> 00:13:56,200
我们的一个输入 batch-size 跟 input dim

361
00:13:58,166 --> 00:13:59,566
那 devices 没有

362
00:13:59,566 --> 00:14:00,266
所以我们现在

363
00:14:00,266 --> 00:14:01,566
要定义一个 devices

364
00:14:01,600 --> 00:14:04,166
是在整个昇腾的硬件上面去跑的

365
00:14:09,133 --> 00:14:11,966
PU 我们现在指定第三个 NPU

366
00:14:11,966 --> 00:14:13,400
因为我们刚才看到了

367
00:14:13,400 --> 00:14:14,266
ZOMI 查了一下

368
00:14:14,266 --> 00:14:15,833
只有第三个 PU 是空的

369
00:14:15,833 --> 00:14:16,833
其他的 NPU

370
00:14:16,833 --> 00:14:17,933
都被占用了

371
00:14:20,266 --> 00:14:21,833
否则如果都被占用了

372
00:14:21,833 --> 00:14:23,466
我们就在 CPU 里面去跑

373
00:14:23,466 --> 00:14:26,066
然后我们现在定义 MoE 的一个对象

374
00:14:26,066 --> 00:14:27,466
或者对 MoE 的变量

375
00:14:33,533 --> 00:14:35,133
Moe Moe

376
00:14:35,466 --> 00:14:37,500
对了 Moe 的 classics

377
00:14:37,633 --> 00:14:38,300
那基本上

378
00:14:38,333 --> 00:14:39,433
所有都定义完了

379
00:14:39,433 --> 00:14:40,700
不知道这里面为什么

380
00:14:40,733 --> 00:14:42,533
会有这么一条斜杠哦

381
00:14:44,666 --> 00:14:46,233
这个（o）是小写 QAQ

382
00:14:46,233 --> 00:14:48,300
没关系我们现在把它改成小写

383
00:14:48,800 --> 00:14:49,366
那改成小写

384
00:14:49,366 --> 00:14:50,066
就好了然后

385
00:14:50,066 --> 00:14:52,733
我们现在来真正的去打开一个

386
00:14:52,766 --> 00:14:54,333
对应的训练

387
00:14:54,333 --> 00:14:54,666
训练

388
00:14:54,666 --> 00:14:57,566
可能我们简单的做一个小的迭代

389
00:15:02,266 --> 00:15:04,133
那输出一个 output shape

390
00:15:08,066 --> 00:15:10,366
约定好它的一个输出的格式

391
00:15:12,166 --> 00:15:13,733
有了一个训练之后

392
00:15:13,733 --> 00:15:16,600
我们还是要执行一个推理的 Moe 的 Evo

393
00:15:16,833 --> 00:15:20,033
eval 然后 output 因为整个

394
00:15:21,766 --> 00:15:23,466
它不需要一个 loss

395
00:15:23,466 --> 00:15:24,633
所以我们就自 0

396
00:15:24,633 --> 00:15:27,033
然后等于 Moe

397
00:15:29,633 --> 00:15:32,233
那这里我们要声明是 traing

398
00:15:34,666 --> 00:15:35,366
那现在

399
00:15:35,400 --> 00:15:36,066
我们基本上

400
00:15:36,066 --> 00:15:37,233
已经执行完所有的

401
00:15:37,233 --> 00:15:38,700
或者写完所有的代码了

402
00:15:38,733 --> 00:15:40,633
那基本上所有的代码的注释

403
00:15:40,633 --> 00:15:42,033
ZOMI 后面会加上去

404
00:15:42,033 --> 00:15:44,466
包括每一个到底是属于什么类型

405
00:15:44,466 --> 00:15:45,766
然后他的 xxxx 是怎么样的

406
00:15:45,800 --> 00:15:46,633
我们现在

407
00:15:46,633 --> 00:15:49,233
已经实现的时间已经蛮长的了

408
00:15:49,233 --> 00:15:51,100
所以我们马上把这个代码

409
00:15:51,133 --> 00:15:53,433
推到我们的一个具体的硬件上面

410
00:15:53,433 --> 00:15:55,033
就我们的昇腾的 NPU

411
00:15:56,000 --> 00:15:58,333
现在我们用 NPU SMI

412
00:15:58,333 --> 00:16:01,766
看一下昇腾的相关的硬件有哪些

413
00:16:01,833 --> 00:16:03,166
首先放在左边这个图

414
00:16:03,200 --> 00:16:04,433
可以看到诶

415
00:16:04,800 --> 00:16:06,200
4567 卡是空的

416
00:16:06,200 --> 00:16:08,566
所以我们 LS vim moe

417
00:16:09,133 --> 00:16:12,366
然后把对应的卡进行一些修改一下

418
00:16:12,966 --> 00:16:14,433
代码有点小有点丑

419
00:16:15,933 --> 00:16:18,200
然后 NPU4

420
00:16:18,333 --> 00:16:20,366
使用第四张 NPU 卡

421
00:16:21,733 --> 00:16:23,200
然后执行一下

422
00:16:26,366 --> 00:16:28,333
那打开对应的代码

423
00:16:28,333 --> 00:16:29,366
我们看一下代码

424
00:16:29,366 --> 00:16:29,933
这里面

425
00:16:29,933 --> 00:16:32,600
其实内容已经蛮多的了

426
00:16:32,600 --> 00:16:33,633
但是蛮有意思的

427
00:16:33,633 --> 00:16:35,066
就是 ZOMI 觉得

428
00:16:35,066 --> 00:16:37,033
这可能我们的迭代次数不够多

429
00:16:37,033 --> 00:16:38,033
那我们迭代次数

430
00:16:38,033 --> 00:16:40,333
是 100 甚至 1,000 了

431
00:16:40,366 --> 00:16:42,033
那就 1,000 个迭代

432
00:16:42,033 --> 00:16:44,833
然后不断的去计算我们的一个 moe

433
00:16:44,966 --> 00:16:46,133
那迭代过程当中

434
00:16:46,133 --> 00:16:48,566
我们就可以去看一下那个 NPU 的

435
00:16:48,566 --> 00:16:49,533
infar 看一下我们的

436
00:16:49,533 --> 00:16:51,866
NPU 卡是否真正的跑起来

437
00:16:51,866 --> 00:16:52,266
另外的话

438
00:16:52,266 --> 00:16:55,866
这里面我们加上 training 的 output

439
00:16:57,666 --> 00:17:02,033
还有一个 training 的 auxiliary loss

440
00:17:04,033 --> 00:17:05,133
那有了这个之后

441
00:17:05,166 --> 00:17:07,800
你会发现我们再加一个 print

442
00:17:08,666 --> 00:17:09,933
做一个分隔符

443
00:17:11,133 --> 00:17:12,366
那分隔符完之后

444
00:17:12,366 --> 00:17:13,766
我们看一下整体的代码

445
00:17:13,766 --> 00:17:14,733
代码里面蛮有意思的

446
00:17:14,733 --> 00:17:16,066
就是我们其实刚才

447
00:17:16,066 --> 00:17:17,733
已经把路由已经设置好了

448
00:17:17,766 --> 00:17:19,566
路由就通过我们的一个 Softmax

449
00:17:19,566 --> 00:17:20,666
跟一个 gate 网络

450
00:17:20,666 --> 00:17:21,366
那 gate 网络

451
00:17:21,400 --> 00:17:23,800
实际上是一个 linear 的一个先进程

452
00:17:24,666 --> 00:17:26,966
有了一系列的辅助损失函数之后

453
00:17:27,000 --> 00:17:28,633
我们分配了一系列的专家

454
00:17:28,633 --> 00:17:29,766
然后进行初始化

455
00:17:29,800 --> 00:17:31,566
获取每个专家的分配的样本

456
00:17:31,566 --> 00:17:33,733
然后进行一个容量的控制

457
00:17:33,966 --> 00:17:35,666
然后进行一个专家处理

458
00:17:35,666 --> 00:17:37,466
然后再进行一个累加输出

459
00:17:37,466 --> 00:17:38,933
那具体代码比较简单

460
00:17:38,966 --> 00:17:40,033
才 100 来行

461
00:17:40,200 --> 00:17:42,133
那我们现在来把这堆代码破取回去

462
00:17:42,133 --> 00:17:43,766
我们的刚才的终端

463
00:17:44,233 --> 00:17:46,633
我们现在在终端里面先清掉

464
00:17:46,633 --> 00:17:50,433
然后 watch_n 0.1 秒

465
00:17:50,433 --> 00:17:52,533
每隔 0.1 秒来进行一个刷新

466
00:17:52,566 --> 00:17:56,166
我们的一个 NPU SMI 的 info

467
00:17:57,933 --> 00:17:58,600
下面可以看到

468
00:17:58,600 --> 00:18:00,166
这个基本上是实时刷新的

469
00:18:00,166 --> 00:18:02,233
我们后面的会跑在第四张卡

470
00:18:02,366 --> 00:18:04,666
于是呢我们现在也是清除掉

471
00:18:04,766 --> 00:18:07,933
然后把我们的一个代码跑起来

472
00:18:09,800 --> 00:18:10,333
跑之前

473
00:18:10,333 --> 00:18:12,533
我们还是要把代码给丢过来的

474
00:18:13,333 --> 00:18:14,366
丢完代码之后

475
00:18:14,366 --> 00:18:16,166
我们现在来执行这条命令

476
00:18:19,333 --> 00:18:21,533
可以看到我们的代码已经跑起来了

477
00:18:21,533 --> 00:18:23,533
后面会有一堆的输出

478
00:18:24,766 --> 00:18:26,033
跑在第四张卡

479
00:18:26,033 --> 00:18:26,666
我们看一下

480
00:18:26,666 --> 00:18:29,033
第四张卡已经明确的跑起来了

481
00:18:29,033 --> 00:18:30,533
再用我们对应的显存

482
00:18:30,600 --> 00:18:31,400
那这里面

483
00:18:31,400 --> 00:18:32,433
我们回到这

484
00:18:32,433 --> 00:18:33,366
里面可以看到

485
00:18:33,433 --> 00:18:35,366
整体的我们的一个 training 的 output

486
00:18:35,400 --> 00:18:36,433
基本上已经输出了

487
00:18:36,433 --> 00:18:38,666
然后 eval 的 output 也输出了

488
00:18:38,666 --> 00:18:39,666
整体来说

489
00:18:39,666 --> 00:18:41,666
这个代码已经运行完了

490
00:18:42,200 --> 00:18:43,033
那今天的内容

491
00:18:43,033 --> 00:18:43,833
比较简单

492
00:18:43,833 --> 00:18:45,466
主要是跟大家一起去看了一下

493
00:18:45,466 --> 00:18:47,433
对应的这个 MoE 的代码

494
00:18:47,433 --> 00:18:48,100
那这些代码

495
00:18:48,133 --> 00:18:49,966
其实相对特别的简单

496
00:18:49,966 --> 00:18:51,566
首先我们加载了一系列东西

497
00:18:51,566 --> 00:18:53,666
特别是叫跑起 NPU 的时候

498
00:18:53,666 --> 00:18:56,500
我们需要 import touch NPU 生成的机器

499
00:18:56,533 --> 00:18:58,833
然后定义了一个简单的 expert

500
00:18:58,833 --> 00:18:59,666
这个 expert

501
00:18:59,666 --> 00:19:00,933
有一个线性程

502
00:19:00,966 --> 00:19:02,033
然后加一个 GELU

503
00:19:02,033 --> 00:19:03,500
然后再加一个线性程

504
00:19:03,566 --> 00:19:04,600
从小到大

505
00:19:04,766 --> 00:19:07,000
然后再定义真正的 MoE 的架构了

506
00:19:07,000 --> 00:19:08,033
MoE 首先

507
00:19:08,033 --> 00:19:10,733
有一系列的这种所谓的变量

508
00:19:10,766 --> 00:19:11,533
主要两个变量

509
00:19:11,533 --> 00:19:12,400
一个是路由

510
00:19:12,400 --> 00:19:14,333
另外一个是专家的集合

511
00:19:14,333 --> 00:19:15,133
那这个专家

512
00:19:15,133 --> 00:19:16,633
下面我们有一个超参

513
00:19:16,633 --> 00:19:18,166
是八个专家

514
00:19:18,200 --> 00:19:19,166
八个专家之后

515
00:19:19,166 --> 00:19:19,733
下面的内容

516
00:19:19,733 --> 00:19:22,166
已经跟大家已经刚才解释过了

517
00:19:22,166 --> 00:19:23,533
今天就不再解释

518
00:19:23,566 --> 00:19:25,366
那今天的代码的演示

519
00:19:25,366 --> 00:19:26,466
就先到这为止

520
00:19:26,466 --> 00:19:26,966
谢谢各位

521
00:19:27,000 --> 00:19:27,800
拜了个拜

