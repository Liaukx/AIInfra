<!--Copyright © ZOMI 适用于[License](https://github.com/Infrasys-AI/AIInfra)版权许可-->

# 06.大模型压缩

大模型压缩技术正迎来动态化与硬件协同的革新浪潮。面对千亿级参数模型的部署挑战，量化技术突破硬件限制，蒸馏技术通过师生模型架构实现知识高效迁移，最新动态蒸馏策略可根据任务复杂度自适应调整蒸馏强度，让小模型继承大模型 95% 以上的能力；剪枝技术从静态走向动态，结构化与非结构化剪枝结合自适应阈值调整。硬件感知压缩成为边缘部署关键，多技术协同推动大模型在金融、医疗等垂直行业轻量化落地，开启 “小而精” 的实用化新阶段。

## 内容大纲


## 备注

文字课程开源在 [AI Infra](https://infrasys-ai.github.io/aiinfra-docs)，系列视频托管[B 站](https://space.bilibili.com/517221395)和[油管](https://www.youtube.com/@ZOMI666/playlists)，PPT 开源在[github](https://github.com/Infrasys-AI/AIInfra/)，欢迎引用！

> 欢迎大家使用的过程中发现 bug 或者勘误直接提交 PR 到开源社区哦！
>
> 请大家尊重开源和 ZOMI 和贡献者们的努力，引用 PPT 的内容请规范转载标明出处哦！
