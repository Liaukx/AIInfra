1
00:00:00,000 --> 00:00:03,133
内容/录制:Z0MI 酱，视频后期/字幕:岛酱

2
00:00:03,700 --> 00:00:04,700
hello 大家好

3
00:00:04,700 --> 00:00:05,700
大家有没有发现

4
00:00:05,700 --> 00:00:07,100
工作当中压垮你

5
00:00:07,100 --> 00:00:08,900
其实不是你的工作本身

6
00:00:08,900 --> 00:00:10,533
而是你的责任心

7
00:00:15,700 --> 00:00:16,866
那带着这个责任心

8
00:00:16,866 --> 00:00:18,100
ZOMI 还是要顽强

9
00:00:18,100 --> 00:00:21,466
更新完在整个 AI Infra 相关的知识

10
00:00:21,466 --> 00:00:22,033
那今天

11
00:00:22,033 --> 00:00:23,333
来重点分享一下
 
12
00:00:23,333 --> 00:00:25,500
HPC 的一个网络的洞察

13
00:00:25,533 --> 00:00:27,800
因为在整个 AI Infra 的知识里面

14
00:00:27,800 --> 00:00:28,966
现在

15
00:00:28,966 --> 00:00:29,800
已经来到

16
00:00:29,800 --> 00:00:32,433
对于整个集群的互联

17
00:00:32,433 --> 00:00:34,733
网络的相关的知识里面

18
00:00:34,733 --> 00:00:36,666
那在整个知识结构体系里面

19
00:00:36,666 --> 00:00:37,466
今天

20
00:00:37,466 --> 00:00:38,533
或者这一系列

21
00:00:38,533 --> 00:00:40,400
重点的去看一下 L2 的算力

22
00:00:40,400 --> 00:00:43,500
底座相关的网络相关的内容

23
00:00:43,500 --> 00:00:44,733
在 AI system

24
00:00:44,733 --> 00:00:46,933
AI 系统里面的计算已经讲完

25
00:00:46,933 --> 00:00:47,900
在 AI Infra 里面

26
00:00:47,900 --> 00:00:50,066
重点的去打开网络

27
00:00:50,100 --> 00:00:52,333
那正式打开今天的视频之前

28
00:00:52,333 --> 00:00:54,666
其实要提个问题

29
00:00:54,666 --> 00:00:58,600
就是我搞 AI 跟 HPC 有什么关系

30
00:00:58,600 --> 00:01:01,800
为什么要了解 HPC 的组网方案

31
00:01:01,900 --> 00:01:03,000
搞 AI 系统

32
00:01:03,000 --> 00:01:05,733
搞 AI GPU 的组网方案就不行了吗

33
00:01:05,733 --> 00:01:07,466
跟 HPC 啥关系

34
00:01:07,533 --> 00:01:10,533
在整个 AI 集群的组网思路

35
00:01:10,533 --> 00:01:12,266
就跟集群跟组网相关

36
00:01:12,266 --> 00:01:13,733
现在已经来到了第二个内容

37
00:01:13,733 --> 00:01:16,700
看一下 HPC 的超算的相关的洞察

38
00:01:16,700 --> 00:01:17,666
今天的视频

39
00:01:17,666 --> 00:01:19,700
分开两个内容跟大家去分享

40
00:01:19,700 --> 00:01:22,833
第一个就是美国的 top 超算的洞察

41
00:01:22,833 --> 00:01:25,100
那这个资料呢中你能够找到比较多

42
00:01:25,100 --> 00:01:25,466
第二个

43
00:01:25,466 --> 00:01:26,933
就是中国 top 超算的洞察

44
00:01:26,933 --> 00:01:29,266
这个资料说实话找的比较少

45
00:01:29,266 --> 00:01:30,400
网上也比较少

46
00:01:30,400 --> 00:01:32,533
只能拿出一小部分中米能找到

47
00:01:32,533 --> 00:01:34,733
跟大家做个简单的分享

48
00:01:35,000 --> 00:01:35,633
第一个内容呢就

49
00:01:35,633 --> 00:01:39,033
是美国的 top 的超算相关的洞察

50
00:01:39,033 --> 00:01:39,600
发现

51
00:01:39,600 --> 00:01:41,433
其实只要谈到美国

52
00:01:41,433 --> 00:01:42,733
或者全球的 top 超算

53
00:01:42,733 --> 00:01:44,700
基本上会去看一个榜单

54
00:01:44,700 --> 00:01:46,733
叫做 TOP500 的榜单

55
00:01:46,766 --> 00:01:47,866
最新的这个榜单

56
00:01:47,866 --> 00:01:49,133
其实在这条链接

57
00:01:49,133 --> 00:01:50,600
大家可以自己去看一下

58
00:01:50,600 --> 00:01:52,900
2025 年的 6 月 12 号

59
00:01:52,900 --> 00:01:54,333
TOP500 的这个组织

60
00:01:54,333 --> 00:01:55,300
就正式发布

61
00:01:55,300 --> 00:01:56,400
第 65 期

62
00:01:56,400 --> 00:02:00,033
全球超级计算机的 500 强的榜单

63
00:02:00,033 --> 00:02:00,933
那从这个榜单

64
00:02:00,933 --> 00:02:03,300
基本上可以看到两个信息

65
00:02:03,300 --> 00:02:05,433
第一个呢就是 AMD 的处理器

66
00:02:05,433 --> 00:02:08,233
基本上已经占了整个 HPC 的一个

67
00:02:08,233 --> 00:02:10,900
首次包揽前两位

68
00:02:10,900 --> 00:02:13,633
包括 EL 的 captain 和 Forntier 的

69
00:02:13,633 --> 00:02:16,666
都是由 AMD 的处理器啊来去承载

70
00:02:16,666 --> 00:02:18,133
那包揽了前两位

71
00:02:18,133 --> 00:02:19,400
成为最大的赢家

72
00:02:19,400 --> 00:02:20,900
而基本上接近一半的 CPU

73
00:02:20,900 --> 00:02:23,033
都是由 AMD 来提供

74
00:02:23,033 --> 00:02:26,300
当然了英特尔呢还是以 294 套

75
00:02:26,300 --> 00:02:28,133
还是微弱的领先

76
00:02:28,133 --> 00:02:30,933
整体的市占率呢是在 HPC 里面第一

77
00:02:30,933 --> 00:02:32,300
所以现在可以看到

78
00:02:32,300 --> 00:02:33,866
全球的超商的市场

79
00:02:33,866 --> 00:02:35,066
已经形成

80
00:02:35,066 --> 00:02:38,266
两雄争霸的一个非常明确的格局

81
00:02:38,266 --> 00:02:38,933
而这个

82
00:02:38,933 --> 00:02:40,300
在前几年

83
00:02:40,300 --> 00:02:41,833
应该是在 19 年的时候

84
00:02:41,833 --> 00:02:43,633
还是以英特尔为主

85
00:02:43,633 --> 00:02:45,100
那最近这五年

86
00:02:45,100 --> 00:02:47,700
AMD 追赶的非常的快

87
00:02:47,800 --> 00:02:49,200
回到今天要分享的内容

88
00:02:49,200 --> 00:02:53,000
主要是把 TOP500 全球的前四个

89
00:02:53,000 --> 00:02:53,666
就是第一个

90
00:02:53,666 --> 00:02:55,600
第二个第三个跟第四个

91
00:02:55,600 --> 00:02:56,833
单独的拿出来看一下

92
00:02:56,833 --> 00:02:58,933
他们的一个具体的组网的方案

93
00:02:58,933 --> 00:02:59,333
这个

94
00:02:59,333 --> 00:02:59,633
叫做

95
00:02:59,633 --> 00:03:02,300
全球四大的 E 级超算的整体的架构

96
00:03:02,300 --> 00:03:03,900
那基本上会发现哦

97
00:03:03,900 --> 00:03:06,033
就从下面的一些细节或者文字里

98
00:03:06,033 --> 00:03:06,866
可以看到

99
00:03:06,866 --> 00:03:09,300
基本上都会一个 CPU 加 GPU 的架构

100
00:03:09,300 --> 00:03:10,266
那 GPU 之间

101
00:03:10,266 --> 00:03:11,366
在超算领域

102
00:03:11,366 --> 00:03:13,300
基本上全部都会采用 full mesh

103
00:03:13,300 --> 00:03:14,266
一个连接

104
00:03:14,266 --> 00:03:15,433
整体的网络

105
00:03:15,433 --> 00:03:16,300
要不采用 DF

106
00:03:16,300 --> 00:03:19,933
或者 DF+相关的一个组网的方案

107
00:03:19,933 --> 00:03:21,433
那现在来看一下

108
00:03:21,633 --> 00:03:22,000
第一个

109
00:03:22,000 --> 00:03:23,466
就是 El captain

110
00:03:23,466 --> 00:03:25,700
那 CPU 主要是采用 AMD

111
00:03:25,700 --> 00:03:27,466
然后用了 6 个 GPU

112
00:03:27,466 --> 00:03:28,000
整体

113
00:03:28,000 --> 00:03:29,600
可以看一下右边的这个图

114
00:03:29,600 --> 00:03:30,533
网络模型

115
00:03:30,533 --> 00:03:32,133
单节点类的一个拓扑

116
00:03:32,133 --> 00:03:35,400
基本上 6 个 GPU 做一个 full Mesh 的结构

117
00:03:35,400 --> 00:03:37,033
具体呢 GPU 跟 GPU

118
00:03:37,033 --> 00:03:38,833
D-D 的一个带宽

119
00:03:38,833 --> 00:03:40,800
就是 256 Gbps

120
00:03:40,866 --> 00:03:42,200
那了解完

121
00:03:42,200 --> 00:03:44,400
第一个全球第一大超算之后

122
00:03:44,400 --> 00:03:46,433
看一下全球第二大超算

123
00:03:46,433 --> 00:03:47,333
那第二大超算

124
00:03:47,333 --> 00:03:49,933
就是 froniter

125
00:03:49,933 --> 00:03:53,266
同样是由 AMD 提供的 CPU

126
00:03:53,266 --> 00:03:53,900
那这里面

127
00:03:53,900 --> 00:03:56,400
可能跟刚才比较有一个最大的区别

128
00:03:56,400 --> 00:03:58,500
就是只有四个 GPU

129
00:03:58,500 --> 00:03:59,700
那四个 GPU 之间

130
00:03:59,700 --> 00:04:01,633
采用的是一个 full Mesh 的结构

131
00:04:01,633 --> 00:04:02,466
大家可以看到

132
00:04:02,466 --> 00:04:05,600
GPU 跟 GPU 不管是刚才 top one 的 captain

133
00:04:05,600 --> 00:04:08,600
froniter 呢都采用的是一个 full mesh 的结构

134
00:04:08,600 --> 00:04:12,666
然后 D-D 的一个带宽呢是 200 Gbps

135
00:04:12,700 --> 00:04:14,100
第三个的主要算力

136
00:04:14,100 --> 00:04:18,066
这是由英特尔提供的 Aurova 北极光

137
00:04:18,066 --> 00:04:20,200
里面有两个 CPU 加 6 个 GPU

138
00:04:20,200 --> 00:04:21,100
那 GPU 之间

139
00:04:21,100 --> 00:04:23,133
采用是一个 full Mesh 的结构

140
00:04:23,133 --> 00:04:25,066
从下面这个图可以看到

141
00:04:25,066 --> 00:04:28,433
两块英特尔的 CPU 加 6 块 GPU

142
00:04:28,433 --> 00:04:29,666
那 GPU 跟 GPU 之间

143
00:04:29,666 --> 00:04:32,933
同样的是采用 full Mesh 全连接的方式

144
00:04:32,933 --> 00:04:34,066
D-D 的带宽

145
00:04:34,066 --> 00:04:36,033
其实可以去到 400 Gbps

146
00:04:36,033 --> 00:04:37,233
那第四个

147
00:04:37,233 --> 00:04:38,900
最夸张的就是它的 D-D

148
00:04:38,900 --> 00:04:40,233
带宽

149
00:04:40,400 --> 00:04:41,500
这个呢第四个

150
00:04:41,500 --> 00:04:42,400
就是 Jupiter

151
00:04:42,400 --> 00:04:45,900
采用的是英伟达作为整体的供应商

152
00:04:45,900 --> 00:04:46,666
啊那这里面

153
00:04:46,666 --> 00:04:48,400
可以看一下右边的这个图

154
00:04:48,400 --> 00:04:51,133
具体呢采用四个 CPU 加四个 GPU

155
00:04:51,133 --> 00:04:52,433
作为一个 full Mesh

156
00:04:52,433 --> 00:04:54,200
那 CPU 呢采用的是一个 ARM

157
00:04:54,200 --> 00:04:56,600
一个 Grace 跟 hope 的架构

158
00:04:56,600 --> 00:04:58,400
那 D-D 的一个带宽

159
00:04:58,400 --> 00:05:00,466
可以去到 900Gbps

160
00:05:00,466 --> 00:05:01,933
非常的夸张

161
00:05:01,933 --> 00:05:02,600
基本上

162
00:05:02,600 --> 00:05:03,633
除了带宽猛兽

163
00:05:03,633 --> 00:05:05,733
它也是一个计算猛兽

164
00:05:05,733 --> 00:05:08,100
那了解完刚才的四大超商之后

165
00:05:08,100 --> 00:05:09,333
大家有没有发现一个点

166
00:05:09,333 --> 00:05:11,000
就是四大超算

167
00:05:11,000 --> 00:05:13,233
都是采用 Dragonfly 这个组网

168
00:05:13,233 --> 00:05:15,466
所以叫做 DF 的组网

169
00:05:15,466 --> 00:05:15,900
那下面

170
00:05:15,900 --> 00:05:16,700
来看一下

171
00:05:16,700 --> 00:05:18,733
Dragonfly 的这种组网拓扑

172
00:05:18,733 --> 00:05:20,300
到底有哪些优势

173
00:05:20,300 --> 00:05:23,166
那其实呢 ZOMI 总结了三个点

174
00:05:23,166 --> 00:05:23,400
一个

175
00:05:23,400 --> 00:05:26,033
就是通信的延时相对来说比较低

176
00:05:26,033 --> 00:05:27,533
因为整体 Dragonfly 的拓扑

177
00:05:27,533 --> 00:05:29,900
大部分呢都采用两级的全互联

178
00:05:29,900 --> 00:05:31,600
所以可以看一下右边的这个图

179
00:05:31,600 --> 00:05:34,400
密密麻麻的进行了一个全互联的方式

180
00:05:34,400 --> 00:05:36,100
整体的网络直径是比较低

181
00:05:36,100 --> 00:05:38,500
平均的通信的时延也比较低

182
00:05:38,533 --> 00:05:39,200
第二点来说

183
00:05:39,200 --> 00:05:40,666
就是成本来看

184
00:05:40,666 --> 00:05:42,833
对于胖树或者 fat tree 这种结构

185
00:05:42,833 --> 00:05:44,433
说实话或者这种拓扑

186
00:05:44,433 --> 00:05:46,766
它是相对来说比较节省成本

187
00:05:46,766 --> 00:05:49,866
当整个超算的节点越来越多的时候

188
00:05:49,866 --> 00:05:52,066
胖树的路由和带宽的数量

189
00:05:52,066 --> 00:05:53,433
是急剧的膨胀

190
00:05:53,466 --> 00:05:55,133
但是呢 Dragonfly 这种方式

191
00:05:55,133 --> 00:05:55,266


192
00:05:55,266 --> 00:05:58,233
其实有效的去节省全局的光纤链路

193
00:05:58,233 --> 00:06:00,266
和对应的交换机

194
00:06:00,600 --> 00:06:02,333
第三个呢就是网络的吞吐

195
00:06:02,333 --> 00:06:04,066
基本上可以做到无损

196
00:06:04,133 --> 00:06:06,133
那这个后面会重点的去展开

197
00:06:06,133 --> 00:06:07,400
网络拓扑的时候

198
00:06:07,400 --> 00:06:08,033
跟大家讲到

199
00:06:08,033 --> 00:06:09,400
简单的了解

200
00:06:09,400 --> 00:06:10,100
这期视频

201
00:06:10,100 --> 00:06:13,233
是在 HPC 的网络的大概的组网的方案

202
00:06:13,233 --> 00:06:14,800
那其实呢你会发现

203
00:06:14,800 --> 00:06:17,700
刚才啊 DF 跟 DF+的一个具体的拓扑

204
00:06:17,700 --> 00:06:19,233
其实也有它的一个不足

205
00:06:19,233 --> 00:06:19,866
那大家发现

206
00:06:19,866 --> 00:06:21,733
在整个拓扑里面

207
00:06:21,733 --> 00:06:24,433
其中的一个圈圈里面的一个小点

208
00:06:24,433 --> 00:06:27,466
代表的是一台机器或者一个计算节点

209
00:06:27,466 --> 00:06:30,066
那这里面呢就会分为很多个组

210
00:06:30,066 --> 00:06:31,633
那假设这个圈圈作为一个组

211
00:06:31,633 --> 00:06:32,833
这个圈圈作为一个组

212
00:06:32,866 --> 00:06:34,100
这个圈圈也做一个组

213
00:06:34,100 --> 00:06:36,533
基本上你会发现很多个组组间

214
00:06:36,533 --> 00:06:38,633
至少有一条直达的链路

215
00:06:38,633 --> 00:06:41,000
那这条直达的链路的带宽是做到最低

216
00:06:41,000 --> 00:06:43,666
而且整体的流量呢需要去绕路

217
00:06:43,733 --> 00:06:44,266
因此

218
00:06:44,266 --> 00:06:48,300
对于整个路由的算法是非常的高

219
00:06:48,300 --> 00:06:50,300
第二个呢就是二分的带宽

220
00:06:50,300 --> 00:06:52,033
实际上没有胖树高

221
00:06:52,033 --> 00:06:53,900
对于一些对抗性的流量

222
00:06:53,900 --> 00:06:56,233
它整体的吞吐率呢会下降

223
00:06:56,233 --> 00:06:58,066
这也是 Dragonfly

224
00:06:58,066 --> 00:06:59,833
一个网络拓扑的不足

225
00:06:59,900 --> 00:07:01,233
但是呢既然它有不足

226
00:07:01,233 --> 00:07:02,533
它也有都有点优势

227
00:07:02,533 --> 00:07:05,033
为什么美国的 HPC 超算

228
00:07:05,033 --> 00:07:05,933
都会采用 DF 块

229
00:07:05,933 --> 00:07:08,700
DF+相关的网络架构

230
00:07:08,766 --> 00:07:10,233
那其实呢主要两点

231
00:07:10,233 --> 00:07:10,633
第一点

232
00:07:10,633 --> 00:07:13,333
就是在大规模的扩展跟成本

233
00:07:13,333 --> 00:07:13,933
跟低延迟

234
00:07:13,933 --> 00:07:16,600
跟高高带宽之间呢做了一个平衡

235
00:07:16,600 --> 00:07:18,133
基本上呢在 HPC 里面

236
00:07:18,133 --> 00:07:20,000
Dragonfly 这种网络拓扑

237
00:07:20,000 --> 00:07:22,633
是公认的业界的最佳水平对 

238
00:07:22,633 --> 00:07:24,300
于网络拓扑的选择

239
00:07:24,300 --> 00:07:26,433
实际上是在一个工程成本

240
00:07:26,433 --> 00:07:27,466
还通信的效率

241
00:07:27,466 --> 00:07:30,800
还有故障的容忍度进行一个权衡

242
00:07:30,800 --> 00:07:32,433
所以说 Dragonfly

243
00:07:32,433 --> 00:07:35,100
其实非常的方便做大规模的扩展

244
00:07:35,100 --> 00:07:37,600
而成本呢还是相对的有效

245
00:07:37,600 --> 00:07:40,100
而且延迟跟带宽也是比较低

246
00:07:40,733 --> 00:07:41,533
当聊到这里

247
00:07:41,533 --> 00:07:44,000
其实 ZOMI 跟大家啊之前也有一个疑问

248
00:07:44,000 --> 00:07:45,633
为什么我国的超算

249
00:07:45,633 --> 00:07:46,600
或者现在看到

250
00:07:46,600 --> 00:07:48,333
很多的 AI 的超算

251
00:07:48,333 --> 00:07:50,833
不去用 Dragonfly 这种网络拓扑

252
00:07:50,833 --> 00:07:52,500
那后面呢会详细的展开

253
00:07:52,500 --> 00:07:54,533
这里面呢只是对 HPC

254
00:07:54,533 --> 00:07:57,200
ZOMI 的做一个简单的洞察

255
00:07:57,200 --> 00:07:57,800
那第二个

256
00:07:57,800 --> 00:07:58,266
看一下

257
00:07:58,266 --> 00:08:00,733
中国的拓扑的超算的一个相关的洞察

258
00:08:00,733 --> 00:08:02,466
那这个内容呢其实比较少

259
00:08:02,466 --> 00:08:05,666
因为从 2025 年的 6 月 12 号之后

260
00:08:05,666 --> 00:08:08,433
中国啊就全球的 TOP500 的超算的评比

261
00:08:08,433 --> 00:08:11,033
中国表示不再参与更新

262
00:08:11,033 --> 00:08:12,933
那以前的可能会放着

263
00:08:12,933 --> 00:08:15,533
但是呢新的或者未来的也不再参与

264
00:08:15,533 --> 00:08:16,466
所以相关网上

265
00:08:16,466 --> 00:08:18,866
能找到的资源也会比较少

266
00:08:18,866 --> 00:08:19,333
那第一个

267
00:08:19,333 --> 00:08:20,933
看一下我国

268
00:08:20,933 --> 00:08:23,066
在无锡的神威太湖之光

269
00:08:23,066 --> 00:08:25,000
主要是采用四层的胖树

270
00:08:25,000 --> 00:08:26,100
然后 4:1 的收敛

271
00:08:26,100 --> 00:08:29,633
256 个节点呢组成一个 superPoD

272
00:08:29,633 --> 00:08:31,400
但具体是一个超节点

273
00:08:31,433 --> 00:08:32,700
整体的互联

274
00:08:32,700 --> 00:08:35,033
采用的是一个 Mellanox 一个网卡

275
00:08:35,033 --> 00:08:38,466
加上 36 口的 EDR 的一个自研的交换芯片

276
00:08:38,466 --> 00:08:39,533
那物理的拓扑

277
00:08:39,533 --> 00:08:40,833
采用的是一个胖树

278
00:08:40,833 --> 00:08:41,800
大家从这个图

279
00:08:41,800 --> 00:08:43,633
还有下面这个图也可以看得出来

280
00:08:43,633 --> 00:08:44,400
节点类

281
00:08:44,400 --> 00:08:48,400
基本上就是乘 6*16 的一个全交换的网络

282
00:08:48,466 --> 00:08:51,200
每个节点呢上联 64 条链路

283
00:08:51,200 --> 00:08:52,633
下联呢 256

284
00:08:52,633 --> 00:08:55,233
个节点然后通过上面的核心

285
00:08:55,233 --> 00:08:57,700
进行一个交换网络

286
00:08:57,700 --> 00:08:59,100
那基本上从这个图

287
00:08:59,100 --> 00:09:00,866
也可以看到相关的内容

288
00:09:00,866 --> 00:09:02,633
其中一个小圈圈

289
00:09:02,633 --> 00:09:04,500
或者代表一个节点

290
00:09:04,500 --> 00:09:05,200
然后这里面

291
00:09:05,200 --> 00:09:07,733
代表一个大的 supernode 超节点

292
00:09:07,733 --> 00:09:10,233
然后超节点之间呢是堆叠起来

293
00:09:10,233 --> 00:09:12,100
超节点之间呢会有一个网络

294
00:09:12,100 --> 00:09:13,666
然后多个超节点之间

295
00:09:13,666 --> 00:09:16,400
会通过上层的网络进行组网

296
00:09:16,400 --> 00:09:17,200
那这种方式

297
00:09:17,200 --> 00:09:18,500
就保证整体

298
00:09:18,500 --> 00:09:20,933
呈现一个 4 层的胖树

299
00:09:21,100 --> 00:09:21,866
那第二个

300
00:09:21,866 --> 00:09:23,266
看一下天河

301
00:09:23,266 --> 00:09:25,666
那下面呢就是好不容易找到一个图

302
00:09:25,666 --> 00:09:26,266
那基本上

303
00:09:26,266 --> 00:09:29,466
天河就是以 32 个计算节点

304
00:09:29,466 --> 00:09:30,600
构成一个计算帧

305
00:09:30,600 --> 00:09:31,833
叫做 compute fan

306
00:09:32,000 --> 00:09:34,633
计算帧跟计算帧之间

307
00:09:34,700 --> 00:09:37,433
节点通过一个 32*32 的交换板

308
00:09:37,433 --> 00:09:39,866
进行一个互相的通信

309
00:09:39,866 --> 00:09:42,700
那这里面可以看到有四个计算帧

310
00:09:42,700 --> 00:09:43,600
四个计算帧

311
00:09:43,600 --> 00:09:45,300
就构成了一个计算的机架

312
00:09:45,300 --> 00:09:46,733
叫做 computer work

313
00:09:46,866 --> 00:09:47,666
算的机架

314
00:09:47,666 --> 00:09:50,600
通过 24 个顶层的一个交换机

315
00:09:50,600 --> 00:09:52,400
进行对外的通信

316
00:09:52,400 --> 00:09:55,433
每个交换机呢都有 576 个端口

317
00:09:55,433 --> 00:09:58,333
因此呢计算的一个机架 computer rack

318
00:09:58,333 --> 00:10:00,600
跟交换机通过有缘光缆

319
00:10:00,600 --> 00:10:02,100
进行一个连接

320
00:10:02,100 --> 00:10:02,900
那从这个图

321
00:10:02,900 --> 00:10:04,933
其实看的比较清楚

322
00:10:05,166 --> 00:10:06,266
当然了刚才讲到

323
00:10:06,266 --> 00:10:08,600
整个计算节点的一个互联的网络

324
00:10:08,600 --> 00:10:09,600
都是自研

325
00:10:09,600 --> 00:10:12,266
第一个自研的就是 NIC 网卡

326
00:10:12,266 --> 00:10:13,833
这个呢就是 NRC

327
00:10:13,833 --> 00:10:15,800
对应的是网络路由的芯片

328
00:10:15,800 --> 00:10:17,500
不管是 NIC 还是 NRC

329
00:10:17,500 --> 00:10:18,433
都是对带宽

330
00:10:18,433 --> 00:10:21,000
引擎和可靠性呢进行了特殊的优化

331
00:10:21,000 --> 00:10:22,033
但是呢怎么自研

332
00:10:22,033 --> 00:10:23,800
其实没有太多的相关的材

333
00:10:23,800 --> 00:10:24,866
料啊那一共

334
00:10:24,866 --> 00:10:26,666
可以看一下右边的这个图

335
00:10:26,666 --> 00:10:30,000
整个天河二号呢有 168 个机柜

336
00:10:30,100 --> 00:10:34,066
其中的 139 个呢就是对应的计算的机柜

337
00:10:34,200 --> 00:10:34,866
那这个时候

338
00:10:34,866 --> 00:10:36,833
可能还是要提出一个问题

339
00:10:36,833 --> 00:10:38,800
为什么国内的 HPC

340
00:10:38,800 --> 00:10:41,200
你会发现国外的或者美国

341
00:10:41,200 --> 00:10:43,433
都是采用 Dragonfly 的一种方式

342
00:10:43,433 --> 00:10:44,733
那国内的 HPC

343
00:10:44,733 --> 00:10:47,800
其实大部分都是采用胖数的结构 why

344
00:10:47,833 --> 00:10:48,666
为什么不一样

345
00:10:48,666 --> 00:10:50,300
为什么国内不采用 Dragonfly

346
00:10:50,300 --> 00:10:51,066
其实呢这里面

347
00:10:51,066 --> 00:10:52,900
ZOMI 做了一个简单的小总结

348
00:10:52,900 --> 00:10:55,800
首先呢中国的超算的节点的规模

349
00:10:55,800 --> 00:10:58,100
大部分都在 1K 到 10k 的节点

350
00:10:58,200 --> 00:10:59,433
这种规模的 HPC

351
00:10:59,433 --> 00:11:00,666
胖出的总体的成本

352
00:11:00,666 --> 00:11:03,100
实际上是基低于 Dragonfly

353
00:11:03,100 --> 00:11:04,533
所以呢第二个点

354
00:11:04,533 --> 00:11:06,700
考虑的是成本的问题

355
00:11:06,700 --> 00:11:07,200
第二点

356
00:11:07,200 --> 00:11:09,500
就是考虑成熟度的问题

357
00:11:09,533 --> 00:11:11,700
因为你会发现中国一开始的超算

358
00:11:11,700 --> 00:11:13,900
是在 Fat-Tree 的一个网络拓扑下面

359
00:11:13,900 --> 00:11:15,133
去做一个研发

360
00:11:15,133 --> 00:11:17,633
因此呢基于胖树呢还加上光互联

361
00:11:17,633 --> 00:11:19,000
然后呢胖树组内

362
00:11:19,000 --> 00:11:20,466
又引入了 3D Torus

363
00:11:20,466 --> 00:11:22,433
这种优化的通信的方式

364
00:11:22,433 --> 00:11:24,800
所以说在这条胖树的结构下面

365
00:11:24,800 --> 00:11:27,200
已经发明了很多的技术点

366
00:11:27,200 --> 00:11:27,600
因此

367
00:11:27,600 --> 00:11:30,233
没有必要去重新研究 Dragonfly

368
00:11:30,400 --> 00:11:31,100
第三个点

369
00:11:31,100 --> 00:11:32,866
其实是最重要最核心

370
00:11:32,866 --> 00:11:34,733
就是胖树的网络拓扑

371
00:11:34,733 --> 00:11:37,200
整体他用的交换机和路由器

372
00:11:37,200 --> 00:11:40,000
是使用工业标准的网络的交换机

373
00:11:40,000 --> 00:11:40,533
这个时候

374
00:11:40,533 --> 00:11:41,833
可以最大程度

375
00:11:41,833 --> 00:11:44,133
去利用国产可替代的组件

376
00:11:44,133 --> 00:11:46,100
降低关键组件的依赖

377
00:11:46,100 --> 00:11:48,133
Dragonfly 的路由器啊其实是独立

378
00:11:48,133 --> 00:11:49,333
它不符合一个普通

379
00:11:49,333 --> 00:11:49,833
的标准

380
00:11:49,833 --> 00:11:51,900
因此你会发现供应链

381
00:11:51,900 --> 00:11:53,600
其实也是受限

382
00:11:53,666 --> 00:11:55,333
超高带宽的一个网络路由

383
00:11:55,333 --> 00:11:57,833
其实在国内是获取不

384
00:11:57,833 --> 00:11:59,066
因此呢你会发现

385
00:11:59,066 --> 00:12:02,333
国内跟国外的 HPC 里面的组网方案

386
00:12:02,333 --> 00:12:04,300
不一样视频呢比较短

387
00:12:04,300 --> 00:12:05,600
因为在 HPC 相关

388
00:12:05,600 --> 00:12:07,933
能找到的内容还是比较少

389
00:12:10,333 --> 00:12:11,266
那现在

390
00:12:11,266 --> 00:12:12,400
因为 WAIC

391
00:12:12,400 --> 00:12:13,533
世界人工智能大会

392
00:12:13,533 --> 00:12:15,266
其实有很多小伙伴访问完

393
00:12:15,266 --> 00:12:16,433
或者去拜访完

394
00:12:16,433 --> 00:12:17,533
去学习完之后

395
00:12:17,533 --> 00:12:19,233
他们回来跟 ZOMI 一起去讨论

396
00:12:19,233 --> 00:12:20,433
说现在的超节点

397
00:12:20,433 --> 00:12:22,800
是借用借鉴 HPC 的设计

398
00:12:22,800 --> 00:12:23,466
其实

399
00:12:23,466 --> 00:12:26,400
很多人对这句话呢是不明所以的 why

400
00:12:26,466 --> 00:12:29,000
为什么现在的 AI 的超节点借鉴 HPC

401
00:12:29,000 --> 00:12:30,333
其实本质上

402
00:12:30,333 --> 00:12:33,066
就是复用 HPC 的一个高速互联的设计

403
00:12:33,066 --> 00:12:34,533
跟通信的优化的经验

404
00:12:34,533 --> 00:12:36,533
说白了就是经验的复制

405
00:12:36,533 --> 00:12:39,133
来去把这些经验呢应对到大模型里面

406
00:12:39,133 --> 00:12:42,633
分布式训练里面的高带宽的要求

407
00:12:42,633 --> 00:12:44,300
所以说现在的超节点

408
00:12:44,300 --> 00:12:45,533
做 scale up

409
00:12:45,666 --> 00:12:48,100
其实真的是借鉴 HPC 里面

410
00:12:48,100 --> 00:12:49,600
很多相关的设计

411
00:12:49,600 --> 00:12:51,033
因为刚才讲到

412
00:12:51,033 --> 00:12:52,600
在传统的 HPC 里面

413
00:12:52,600 --> 00:12:54,433
已经开始引入了 Supernote

414
00:12:54,433 --> 00:12:56,066
超节点相关的概念

415
00:12:56,066 --> 00:12:57,466
那现在的 AI

416
00:12:57,466 --> 00:13:00,066
也是通过这个概念来复制过来

417
00:13:00,066 --> 00:13:01,100
因此你会发现

418
00:13:01,100 --> 00:13:04,633
AI 的超节点就是借鉴 HPC 传统的设计

419
00:13:04,633 --> 00:13:05,800
那借鉴哪些内容

420
00:13:05,800 --> 00:13:08,400
这里面呢就简单的跟大家过一过

421
00:13:08,400 --> 00:13:08,700
第一个

422
00:13:08,700 --> 00:13:12,000
就是通信密集型的负载非常相似

423
00:13:12,000 --> 00:13:13,266
因此呢借鉴了很多

424
00:13:13,266 --> 00:13:15,433
HPC 的相关的网络的设计

425
00:13:15,433 --> 00:13:16,533
那为什么会是会

426
00:13:16,533 --> 00:13:18,333
相似呢是因为在 HPC 里面

427
00:13:18,333 --> 00:13:20,433
经常会去算一些计算流体学

428
00:13:20,433 --> 00:13:21,533
还有分子动力学

429
00:13:21,533 --> 00:13:23,433
相关的计算科学的内容

430
00:13:23,433 --> 00:13:24,433
那这些计算科学

431
00:13:24,433 --> 00:13:27,033
需要频繁的跨接点进行数据的同步

432
00:13:27,033 --> 00:13:28,866
而 AI 的大模型训练

433
00:13:28,866 --> 00:13:31,333
你会发现非常的依赖于 all reduce

434
00:13:31,333 --> 00:13:33,666
all2all 集合通信

435
00:13:33,666 --> 00:13:34,633
那这个时候你会发现

436
00:13:34,633 --> 00:13:38,333
他们通信的习惯和行为是类似

437
00:13:38,333 --> 00:13:39,633
但是通信的包的大小

438
00:13:39,633 --> 00:13:41,200
和通信的频次不一样

439
00:13:41,200 --> 00:13:42,266
至少这里面

440
00:13:42,266 --> 00:13:44,633
是变成了从计算密集型

441
00:13:44,633 --> 00:13:46,233
慢慢的变成了一个计算

442
00:13:46,233 --> 00:13:49,500
跟通信的一个密集型的负载的业务

443
00:13:49,500 --> 00:13:52,233
所以说通信的方式比较像

444
00:13:52,466 --> 00:13:52,866
第二点

445
00:13:52,866 --> 00:13:55,833
就是硬件的架构的技术的迁移

446
00:13:55,833 --> 00:13:57,533
说白了就是对技术

447
00:13:57,533 --> 00:13:59,100
进行一个复用

448
00:13:59,100 --> 00:14:00,200
在 AI 里面

449
00:14:00,200 --> 00:14:01,500
GPU 的显存的带宽

450
00:14:01,500 --> 00:14:04,100
其实远远超于传统的网络

451
00:14:04,100 --> 00:14:05,800
就英伟达的 h 系列

452
00:14:05,800 --> 00:14:08,900
整体的 GPU 的带宽可以去到 900 Gbps

453
00:14:08,900 --> 00:14:12,133
所以说你面的网络的带宽很高

454
00:14:12,133 --> 00:14:13,000
那这个时候

455
00:14:13,000 --> 00:14:14,300
跟 HPC

456
00:14:14,300 --> 00:14:16,600
里面需要高级的互联的带宽里面

457
00:14:16,600 --> 00:14:18,500
也是非常的相似

458
00:14:18,566 --> 00:14:19,666
而这里面的 AI

459
00:14:19,666 --> 00:14:20,533
你要做超节点

460
00:14:20,533 --> 00:14:22,900
超节点内的基本是做 scale up

461
00:14:22,900 --> 00:14:26,266
scale up 呢是互相的做一个 full Mesh 的架构

462
00:14:26,266 --> 00:14:28,066
这个呢也是跟刚才讲到

463
00:14:28,066 --> 00:14:30,033
分享美国的这几个超算

464
00:14:30,033 --> 00:14:32,300
你会发现不管是 TOP4

465
00:14:32,300 --> 00:14:35,066
全都是节点内做一个 full Mesh

466
00:14:35,066 --> 00:14:36,466
然后超节点内

467
00:14:36,466 --> 00:14:38,733
尽可能的也是 full mesh 的架构

468
00:14:38,733 --> 00:14:40,200
那非常的符合 Dragonfly

469
00:14:40,200 --> 00:14:41,733
基本上也是做了一个

470
00:14:41,733 --> 00:14:44,100
所有的节点全互联的方式

471
00:14:44,100 --> 00:14:46,000
所以说 AI 的超节点

472
00:14:46,000 --> 00:14:49,066
本质上是 Dragonfly 在单机柜内

473
00:14:49,066 --> 00:14:50,300
整体的缩影

474
00:14:50,300 --> 00:14:51,100
不管怎么样

475
00:14:51,100 --> 00:14:53,300
scale up 或者现在的超算

476
00:14:53,300 --> 00:14:55,433
都是做全互联的方式

477
00:14:55,433 --> 00:14:57,033
才能够把单节点

478
00:14:57,033 --> 00:14:59,300
或者对应的超节点

479
00:14:59,300 --> 00:15:00,733
整体的互联带宽做大

480
00:15:00,733 --> 00:15:02,400
那最后一个最重要

481
00:15:02,400 --> 00:15:04,500
就是工程经验的复用

482
00:15:04,500 --> 00:15:06,300
实际上你会发现 HPC 里面

483
00:15:06,300 --> 00:15:07,733
已经解决了很多 Scale Up

484
00:15:07,733 --> 00:15:09,400
跟资源池化

485
00:15:09,400 --> 00:15:11,600
相关的一些核心的技术点

486
00:15:11,600 --> 00:15:14,633
那这些技术点呢直接给到 AI 的超节点

487
00:15:14,633 --> 00:15:15,433
还直接采用

488
00:15:15,433 --> 00:15:15,800
第二

489
00:15:15,800 --> 00:15:18,233
HPC 常用的一个网络要不是 Dragonfly

490
00:15:18,233 --> 00:15:19,800
要不就是 flat tree

491
00:15:19,800 --> 00:15:20,833
对应的网络拓扑

492
00:15:20,833 --> 00:15:21,833
其实现在

493
00:15:21,833 --> 00:15:23,933
就直接用在 AI 的一个集群

494
00:15:23,933 --> 00:15:26,433
而 HPC 里面定制化的一些网络接口

495
00:15:26,433 --> 00:15:27,600
跟 GPU 呢直连

496
00:15:27,600 --> 00:15:29,066
就是对应的 RDMA

497
00:15:29,066 --> 00:15:31,100
或者 GPU direct 的相关的技术

498
00:15:31,100 --> 00:15:32,533
就直接能够复用

499
00:15:32,533 --> 00:15:34,900
降低整体的数据

500
00:15:34,900 --> 00:15:35,933
通信的开销

501
00:15:35,933 --> 00:15:38,266
那最后一个可能会跟人强相关

502
00:15:38,266 --> 00:15:40,733
就是以前呢在国内国外

503
00:15:40,733 --> 00:15:42,666
做超算的那批工程师

504
00:15:42,666 --> 00:15:45,733
其实大部分呢都是从 HPC 慢慢转型

505
00:15:45,733 --> 00:15:48,933
转向过来做 AI Infra 相关的工程师

506
00:15:48,933 --> 00:15:50,333
所以说通过三个内容

507
00:15:50,333 --> 00:15:51,933
第一个就是工程经验的复用

508
00:15:51,933 --> 00:15:53,533
第二个呢就是硬件的架构

509
00:15:53,533 --> 00:15:54,700
非常容易的搬迁

510
00:15:54,700 --> 00:15:55,200
第三个

511
00:15:55,200 --> 00:15:57,600
就是他的通信的方式非常的像

512
00:15:57,666 --> 00:15:59,633
所以说现在的 AI 的超节点

513
00:15:59,633 --> 00:16:01,666
大部分都是借鉴 HPC 的设计

514
00:16:01,666 --> 00:16:04,400
从而快速把 AI 的超节点做起来

515
00:16:04,400 --> 00:16:06,066
所有的技术都是有延续

516
00:16:06,066 --> 00:16:07,633
而不是凭空创造

517
00:16:07,633 --> 00:16:09,066
因此呢今天的内容

518
00:16:09,066 --> 00:16:10,400
就分享到这里为止

